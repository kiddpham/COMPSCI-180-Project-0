<!DOCTYPE html>
<html>
<head>
    <title>Operation Alpha-Two - DECLASSIFIED</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap');
        @font-face {
            font-family: 'AgencyGothic';
            src: url('../fonts/agencygothicct_medium.otf') format('opentype');
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            background: #0a0a0a;
            background-image: linear-gradient(rgba(0, 255, 0, 0.03) 1px, transparent 1px),
                              linear-gradient(90deg, rgba(0, 255, 0, 0.03) 1px, transparent 1px);
            background-size: 40px 40px;
            font-family: 'AgencyGothic', monospace;
            font-size: 20px;
            margin: 20px;
            color: #00ff41;
            min-height: 100vh;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        .header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 30px; padding: 20px; border: 2px solid #00ff41; background: rgba(0, 0, 0, 0.8); }
        .header h1 { font-size: clamp(1.2rem, 3vw, 1.8rem); font-weight: bold; text-transform: uppercase; letter-spacing: 2px; text-shadow: 0 0 8px #00ff41; }
        .back-button { background: transparent; border: 2px solid #ff0040; color: #ff0040; padding: 8px 16px; text-decoration: none; text-transform: uppercase; font-family: 'JetBrains Mono', monospace; font-size: 10px; font-weight: bold; letter-spacing: 1px; transition: all 0.2s ease; display: inline-block; }
        .back-button:hover { background: #ff0040; color: #000; text-shadow: none; }
        .classification { text-align: center; margin-bottom: 20px; font-family: 'JetBrains Mono', monospace; font-size: 14px; color: #ff0040; text-transform: uppercase; letter-spacing: 3px; border: 1px solid #ff0040; padding: 8px; background: rgba(255, 0, 64, 0.1); }
        .mission-details { margin-bottom: 30px; padding: 20px; border-left: 3px solid #00ff41; background: rgba(0, 255, 65, 0.05); font-family: 'JetBrains Mono', monospace; font-size: 16px; line-height: 1.6; color: #b0ff7a; }
        .mission-objective { margin-bottom: 30px; padding: 15px; border: 1px solid #00ff41; background: rgba(0, 0, 0, 0.5); font-family: 'JetBrains Mono', monospace; font-size: 14px; color: #7fff00; }
        .objective-title { color: #00ff41; font-size: 16px; font-weight: bold; text-transform: uppercase; margin-bottom: 10px; }
        .evidence-section { margin-bottom: 40px; }
        .evidence-title { color: #ff0040; font-family: 'JetBrains Mono', monospace; font-size: 14px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px; padding-bottom: 10px; border-bottom: 1px solid #ff0040; }
        .algorithm-section { background: rgba(0, 0, 0, 0.9); border: 1px solid #00ff41; padding: 20px; margin-bottom: 30px; }
        .algorithm-title { color: #00ff41; font-family: 'JetBrains Mono', monospace; font-size: 16px; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 15px; }
        .algorithm-description { font-family: 'JetBrains Mono', monospace; font-size: 13px; line-height: 1.6; color: #b0ff7a; margin-bottom: 15px; }
        .code-block { background: rgba(0, 0, 0, 0.95); border: 1px solid #00ff41; border-left: 3px solid #ff0040; padding: 20px; margin: 20px 0; font-family: 'JetBrains Mono', monospace; font-size: 12px; line-height: 1.4; color: #b0ff7a; overflow-x: auto; white-space: pre-wrap; }
        .code-title { color: #ff0040; font-size: 14px; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 10px; font-weight: bold; }
        .results-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-bottom: 40px; }
        .image-item { background: rgba(0, 0, 0, 0.9); border: 1px solid #00ff41; padding: 20px; transition: all 0.2s ease; }
        .image-item:hover { box-shadow: 0 0 15px rgba(0, 255, 65, 0.3); border-color: #7fff00; }
        .image-label { color: #00ff41; font-family: 'JetBrains Mono', monospace; font-size: 12px; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 15px; }
        .image-item img { width: 100%; height: auto; border: 1px solid #00ff41; filter: brightness(1.1) contrast(1.1); transition: all 0.2s ease; }
        .image-item img:hover { filter: brightness(1.2) contrast(1.2) drop-shadow(0 0 10px rgba(0, 255, 65, 0.3)); }
        @media (max-width: 768px) { .results-grid { grid-template-columns: 1fr; } }
    </style>
</head>
<body>
    <div class="container">
        <div class="classification">&#9632; DECLASSIFIED - OPERATION ALPHA-TWO &#9632;</div>
        <div class="header"><h1>Operation Alpha-Two: Fun with Filters and Frequencies</h1><a href="../index.html" class="back-button">&#8592; Go Back</a></div>
        <div class="mission-details">&gt; MISSION STATUS: COMPLETE<br>&gt; AGENT: Kidd Pham<br>&gt; OPERATION DATE: [REDACTED]<br>&gt; CLASSIFICATION LEVEL: RESTRICTED ACCESS</div>
        <div class="mission-objective"><div class="objective-title">Mission Objective</div>Advanced computational photography operations involving 2D convolutions, edge detection, frequency domain analysis, hybrid image synthesis, and multi-resolution blending techniques. Mission includes implementation of core filtering algorithms from scratch and application to sophisticated image manipulation protocols.</div>

        <div class="evidence-section">
            <div class="evidence-title">Part 1: Fun with Filters</div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.1: Convolution Implementation Protocol</div>
                <div class="algorithm-description">Implementation of 2D convolution operations using both four-loop and optimized two-loop methodologies. Includes zero-padding implementation and performance comparison with scipy's built-in convolution functions.</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Test Subject: Convolution Validation</div><img src="../images/proj2/1.1/my_convo_blurred_christian.png"></div>
                    <div class="image-item"><div class="image-label">Reference: SciPy Implementation</div><img src="../images/proj2/1.1/scipy_blurred_christian.png"></div>
                </div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Christian Bale - Original</div><img src="../images/proj2/1.1/christian_bale.jpg"></div>
                    <div class="image-item"><div class="image-label">Christian Bale - Dx Operator</div><img src="../images/proj2/1.1/christian_Dx.png"></div>
                    <div class="image-item"><div class="image-label">Christian Bale - Dy Operator</div><img src="../images/proj2/1.1/christian_Dy.png"></div>
                </div>
            </div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.2: Finite Difference Operator</div>
                <div class="algorithm-description">Edge detection implementation using finite difference operators to compute image gradients. The Dx and Dy kernels detect horizontal and vertical edges through discrete differentiation.</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Dx Operator Output</div><img src="../images/proj2/1.2/cameraman_Dx.png"></div>
                    <div class="image-item"><div class="image-label">Dy Operator Output</div><img src="../images/proj2/1.2/cameraman_Dy.png"></div>
                    <div class="image-item"><div class="image-label">Gradient Magnitude</div><img src="../images/proj2/1.2/cameraman_gradient_magnitude.png"></div>
                    <div class="image-item"><div class="image-label">Binary Edge Detection (Threshold: 1.0)</div><img src="../images/proj2/1.2/cameraman_final_binary_edges.png"></div>
                </div>
            </div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.3: Derivative of Gaussian (DoG) Filter</div>
                <div class="algorithm-description">To reduce noise sensitivity inherent in finite difference operators, Gaussian smoothing was applied prior to edge detection. Derivative of Gaussian (DoG) filters were constructed by convolving the Gaussian kernel with Dx and Dy, allowing gradient estimation in a single step.</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Gaussian Kernel (Large)</div><img src="../images/proj2/1.3/gaussian_kernel_large.png"></div>
                    <div class="image-item"><div class="image-label">DoG X Kernel</div><img src="../images/proj2/1.3/DoG_x_kernel_large.png"></div>
                    <div class="image-item"><div class="image-label">DoG Y Kernel</div><img src="../images/proj2/1.3/DoG_y_kernel_large.png"></div>
                </div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Gradient Magnitude (DoG)</div><img src="../images/proj2/1.3/gradient_magnitude_DoG.png"></div>
                    <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 1.0)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG_1.0.png"></div>
                    <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 0.3 – Single)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG_single.png"></div>
                    <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 0.3 – Final)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG.png"></div>
                </div>
                <div class="algorithm-description">Compared to raw finite difference outputs, DoG filtering produces significantly cleaner edges by suppressing high-frequency noise before differentiation. While some fine details are smoothed out, the main structural edges remain sharp and continuous. The prompt asked us to try two different approaches: (1) first blur the image with a Gaussian and then apply finite difference operators, and (2) directly convolve with derivative-of-Gaussian (DoG) filters. The "single" and "final" 0.3-threshold binary edge maps come from these two methods, yet they converge to nearly identical results. This shows that DoG-based edge detection is stable across both formulations when reasonable thresholds are chosen.</div>
            </div>
        </div>

        <div class="evidence-section">
            <div class="evidence-title">Part 2: Fun with Frequencies</div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 2.1: Image Sharpening</div>
                <div class="algorithm-description">Image sharpening was performed using unsharp masking. A blurred image was subtracted from the original to extract high-frequency detail, then scaled and added back to the original. Results are shown with increasing sharpening factors.</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Original (Henry Cavill)</div><img src="../images/proj2/2.1/henry_cavill_original.png"></div>
                    <div class="image-item"><div class="image-label">Sharpened (α=0.5)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_0.5.png"></div>
                    <div class="image-item"><div class="image-label">Sharpened (α=2.0)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_2.0.png"></div>
                    <div class="image-item"><div class="image-label">Sharpened (α=3.0)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_3.0.png"></div>
                </div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Taj Mahal - Original</div><img src="../images/proj2/2.1/taj_original.png"></div>
                    <div class="image-item"><div class="image-label">Taj Mahal - Blurred</div><img src="../images/proj2/2.1/taj_blurred.png"></div>
                    <div class="image-item"><div class="image-label">High Frequency Component</div><img src="../images/proj2/2.1/taj_high_freq.png"></div>
                    <div class="image-item"><div class="image-label">Unsharp Mask</div><img src="../images/proj2/2.1/taj_unsharp_mask.png"></div>
                    <div class="image-item"><div class="image-label">Sharpened Taj Mahal</div><img src="../images/proj2/2.1/taj_sharpened.png"></div>
                </div>
            </div>

            <div class="algorithm-section">
                <div class="algorithm-title">Part 2.2: Hybrid Images</div>
                <div class="algorithm-description">Hybrid images combine low-frequency information from one image with high-frequency details from another. Here, σ=7 was chosen for the low-pass cutoff and σ=5 for the high-pass cutoff. This creates images that appear differently when viewed up close (high-frequency dominates) versus from far away (low-frequency dominates).</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Low-Freq Source (Nutmeg)</div><img src="../images/proj2/2.2/fft_nutmeg_original.png"></div>
                    <div class="image-item"><div class="image-label">High-Freq Source (Derek)</div><img src="../images/proj2/2.2/fft_derek_original.png"></div>
                    <div class="image-item"><div class="image-label">Low-Freq (σ=7)</div><img src="../images/proj2/2.2/fft_low_freq.png"></div>
                    <div class="image-item"><div class="image-label">High-Freq (σ=5)</div><img src="../images/proj2/2.2/fft_high_freq.png"></div>
                    <div class="image-item"><div class="image-label">Fourier – Hybrid</div><img src="../images/proj2/2.2/fft_hybrid.png"></div>
                    <div class="image-item"><div class="image-label">Hybrid Result</div><img src="../images/proj2/2.2/hybrid_image5.png"></div>
                </div>
                <div class="algorithm-description">Fourier analysis confirms that the low-pass Nutmeg retains smooth structural frequencies while Derek’s high-pass image preserves sharp details. Their combination produces a hybrid that reads as Derek up close but Nutmeg from afar, validating the cutoff choices of σ=5 and σ=7.</div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Sad Face</div><img src="../images/proj2/2.2/sad_face.jpg"></div>
                    <div class="image-item"><div class="image-label">Happy Face</div><img src="../images/proj2/2.2/happy_face.jpg"></div>
                    <div class="image-item"><div class="image-label">Hybrid – Sad and Happy</div><img src="../images/proj2/2.2/sad_and_happy.png"></div>
                </div>
                <div class="results-grid">
                    <div class="image-item"><div class="image-label">Sarah</div><img src="../images/proj2/2.2/sarah.jpg"></div>
                    <div class="image-item"><div class="image-label">Kitten</div><img src="../images/proj2/2.2/kitten.jpg"></div>
                    <div class="image-item"><div class="image-label">Hybrid – Sarah and Kitten</div><img src="../images/proj2/2.2/sarah_and_kitten.png"></div>
                </div>
                <div class="algorithm-description">Additional hybrids demonstrate flexibility of the technique. In “Sad and Happy,” low-pass smoothing emphasizes head shape while high-pass features preserve eyes and mouth. In “Sarah and Kitten,” the blending fuses human facial features with animal textures. These results illustrate how careful alignment and cutoff tuning drive perceptual outcomes in hybrid image synthesis.</div>
            </div>
        </div>
    </div>
</body>
</html>
