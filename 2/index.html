<!DOCTYPE html>
<html>
<head>
    <title>Operation Alpha-Two - DECLASSIFIED</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap');
        @font-face {
            font-family: 'AgencyGothic';
            src: url('../fonts/agencygothicct_medium.otf') format('opentype');
        }
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            background: #0a0a0a;
            background-image: 
                linear-gradient(rgba(0, 255, 0, 0.03) 1px, transparent 1px),
                linear-gradient(90deg, rgba(0, 255, 0, 0.03) 1px, transparent 1px);
            background-size: 40px 40px;
            font-family: 'AgencyGothic', monospace;
            font-size: 20px;
            margin: 20px;
            color: #00ff41;
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
            padding: 20px;
            border: 2px solid #00ff41;
            background: rgba(0, 0, 0, 0.8);
        }
        .header h1 {
            font-size: clamp(1.2rem, 3vw, 1.8rem);
            font-weight: bold;
            text-transform: uppercase;
            letter-spacing: 2px;
            text-shadow: 0 0 8px #00ff41;
        }
        .back-button {
            background: transparent;
            border: 2px solid #ff0040;
            color: #ff0040;
            padding: 8px 16px;
            text-decoration: none;
            text-transform: uppercase;
            font-family: 'JetBrains Mono', monospace;
            font-size: 10px;
            font-weight: bold;
            letter-spacing: 1px;
            transition: all 0.2s ease;
            display: inline-block;
        }
        .back-button:hover {
            background: #ff0040;
            color: #000;
            text-shadow: none;
        }
        .classification {
            text-align: center;
            margin-bottom: 20px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 14px;
            color: #ff0040;
            text-transform: uppercase;
            letter-spacing: 3px;
            border: 1px solid #ff0040;
            padding: 8px;
            background: rgba(255, 0, 64, 0.1);
        }
        .mission-details {
            margin-bottom: 30px;
            padding: 20px;
            border-left: 3px solid #00ff41;
            background: rgba(0, 255, 65, 0.05);
            font-family: 'JetBrains Mono', monospace;
            font-size: 16px;
            line-height: 1.6;
            color: #b0ff7a;
        }
        .mission-objective {
            margin-bottom: 30px;
            padding: 15px;
            border: 1px solid #00ff41;
            background: rgba(0, 0, 0, 0.5);
            font-family: 'JetBrains Mono', monospace;
            font-size: 14px;
            color: #7fff00;
        }
        .objective-title {
            color: #00ff41;
            font-size: 16px;
            font-weight: bold;
            text-transform: uppercase;
            margin-bottom: 10px;
        }
        .evidence-section {
            margin-bottom: 40px;
        }
        .evidence-title {
            color: #ff0040;
            font-family: 'JetBrains Mono', monospace;
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 2px;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 1px solid #ff0040;
        }
        .algorithm-section {
            background: rgba(0, 0, 0, 0.9);
            border: 1px solid #00ff41;
            padding: 20px;
            margin-bottom: 30px;
        }
        .algorithm-title {
            color: #00ff41;
            font-family: 'JetBrains Mono', monospace;
            font-size: 16px;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }
        .algorithm-description {
            font-family: 'JetBrains Mono', monospace;
            font-size: 13px;
            line-height: 1.6;
            color: #b0ff7a;
            margin-bottom: 15px;
        }
        .code-block {
            background: rgba(0, 0, 0, 0.95);
            border: 1px solid #00ff41;
            border-left: 3px solid #ff0040;
            padding: 20px;
            margin: 20px 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 12px;
            line-height: 1.4;
            color: #b0ff7a;
            overflow-x: auto;
            white-space: pre-wrap;
        }
        .code-title {
            color: #ff0040;
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
            font-weight: bold;
        }
        .code-comment {
            color: #7fff00;
        }
        .code-keyword {
            color: #00ff41;
        }
        .code-string {
            color: #ffaa00;
        }
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }
        .image-item {
            background: rgba(0, 0, 0, 0.9);
            border: 1px solid #00ff41;
            padding: 20px;
            transition: all 0.2s ease;
        }
        .image-item:hover {
            box-shadow: 0 0 15px rgba(0, 255, 65, 0.3);
            border-color: #7fff00;
        }
        .image-label {
            color: #00ff41;
            font-family: 'JetBrains Mono', monospace;
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }
        .image-item img {
            width: 100%;
            height: auto;
            border: 1px solid #00ff41;
            filter: brightness(1.1) contrast(1.1);
            transition: all 0.2s ease;
        }
        .image-item img:hover {
            filter: brightness(1.2) contrast(1.2) drop-shadow(0 0 10px rgba(0, 255, 65, 0.3));
        }
        .side-by-side {
            display: flex;
            gap: 20px;
            align-items: flex-start;
        }
        .side-by-side .image-item {
            flex: 1;
        }
        .security-footer {
            margin-top: 50px;
            padding: 20px;
            border-top: 1px solid #00ff41;
            text-align: center;
            font-family: 'JetBrains Mono', monospace;
            font-size: 10px;
            color: #7fff00;
            opacity: 0.8;
        }
        @media (max-width: 768px) {
            body {
                margin: 15px;
            }
            .header {
                flex-direction: column;
                gap: 15px;
                text-align: center;
            }
            .results-grid {
                grid-template-columns: 1fr;
            }
            .side-by-side {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="classification">&#9632; DECLASSIFIED - OPERATION ALPHA-TWO &#9632;</div>
        <div class="header">
            <h1>Operation Alpha-Two: Fun with Filters and Frequencies</h1>
            <a href="../index.html" class="back-button">&#8592; Go Back</a>
        </div>
        <div class="mission-details">
            &gt; MISSION STATUS: COMPLETE<br>
            &gt; AGENT: Kidd Pham<br>
            &gt; OPERATION DATE: [REDACTED]<br>
            &gt; CLASSIFICATION LEVEL: RESTRICTED ACCESS
        </div>
        <div class="mission-objective">
            <div class="objective-title">Mission Objective</div>
            Advanced computational photography operations involving 2D convolutions, edge detection, frequency domain analysis, 
            hybrid image synthesis, and multi-resolution blending techniques. Mission includes implementation of core filtering 
            algorithms from scratch and application to sophisticated image manipulation protocols.
        </div>
        <div class="evidence-section">
            <div class="evidence-title">Part 1: Fun with Filters</div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.1: Convolution Implementation Protocol</div>
                <div class="algorithm-description">Implementation of 2D convolution operations using both four-loop and optimized two-loop methodologies. Includes zero-padding implementation and performance comparison with scipy's built-in convolution functions.</div>
                <div class="code-block">
<div class="code-title">Four-Loop Convolution Implementation</div><span class="code-keyword">def</span> <span class="code-keyword">convolution2d_four_loops</span>(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    height, width = image.shape
    kerHeight, kerWidth = kernel.shape
    padHeight, padWidth = kerHeight // 2, kerWidth // 2
    paddedImage = np.pad(image, ((padHeight, padHeight), (padWidth, padWidth)))
    kerFlipped = np.flip(kernel, axis=(0,1))
    result = np.zeros((height, width), dtype=np.float32)
    <span class="code-keyword">for</span> i <span class="code-keyword">in</span> range(height):
        <span class="code-keyword">for</span> j <span class="code-keyword">in</span> range(width):
            runningSum = 0.0
            <span class="code-keyword">for</span> k <span class="code-keyword">in</span> range(kerHeight):
                <span class="code-keyword">for</span> l <span class="code-keyword">in</span> range(kerWidth):
                    runningSum += kerFlipped[k, l] * paddedImage[i +k, j + l]
            result[i, j] = runningSum
    <span class="code-keyword">return</span> result
                </div>
                <div class="code-block">
<div class="code-title">Optimized Two-Loop Implementation</div><span class="code-keyword">def</span> <span class="code-keyword">convolution2d_two_loops</span>(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    height, width = image.shape
    kerHeight, kerWidth = kernel.shape
    padHeight, padWidth = kerHeight // 2, kerWidth // 2
    paddedImage = np.pad(image, ((padHeight, padHeight), (padWidth, padWidth)))
    kerFlipped = np.flip(kernel, axis=(0,1))
    result = np.zeros((height, width), dtype=np.float32)
    <span class="code-keyword">for</span> i <span class="code-keyword">in</span> range(height):
        <span class="code-keyword">for</span> j <span class="code-keyword">in</span> range(width):
            region = paddedImage[i:i+kerHeight, j:j+kerWidth]
            result[i,j] = np.sum(region * kerFlipped)
    <span class="code-keyword">return</span> result
                </div>
                <div class="algorithm-description">
                    Analysis demonstrates a clear hierarchy in running speed: the four-loop implementation exhibits 
                    the slowest runtime, while the two-loop variant achieves superior performance through NumPy's vectorized operations 
                    that eliminate the inner kernel iteration loops. The scipy.signal.convolve2d function surpasses both custom 
                    implementations by leveraging frequency domain computation for larger kernels - exploiting the mathematical 
                    equivalence between spatial domain convolution and frequency domain multiplication via FFT transformations, 
                    resulting in dramatically reduced computational complexity for extensive kernel dimensions.
                    
                    All three implementations contain identical boundary management through zero-padding, applying (kernel_dimension/2) 
                    layers of null values around the image perimeter. This padding strategy results in edge pixels having reduced 
                    neighbor visibility, biasing their convolution outputs toward darker values due to the zero-valued padding 
                    contribution.
                </div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Test Subject: Convolution Validation</div><img src="../images/proj2/1.1/my_convo_blurred_christian.png"></div>
                <div class="image-item"><div class="image-label">Reference: SciPy Implementation</div><img src="../images/proj2/1.1/scipy_blurred_christian.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Christian Bale - Original</div><img src="../images/proj2/1.1/christian_bale.jpg"></div>
                <div class="image-item"><div class="image-label">Christian Bale - Dx Operator</div><img src="../images/proj2/1.1/christian_Dx.png"></div>
                <div class="image-item"><div class="image-label">Christian Bale - Dy Operator</div><img src="../images/proj2/1.1/christian_Dy.png"></div>
            </div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.2: Finite Difference Operator</div>
                <div class="algorithm-description">Edge detection implementation using finite difference operators to compute image gradients. The Dx and Dy kernels detect horizontal and vertical edges through discrete differentiation.</div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Dx Operator Output</div><img src="../images/proj2/1.2/cameraman_Dx.png"></div>
                <div class="image-item"><div class="image-label">Dy Operator Output</div><img src="../images/proj2/1.2/cameraman_Dy.png"></div>
                <div class="image-item"><div class="image-label">Gradient Magnitude</div><img src="../images/proj2/1.2/cameraman_gradient_magnitude.png"></div>
                <div class="image-item"><div class="image-label">Binary Edge Detection (Threshold: 1.0)</div><img src="../images/proj2/1.2/cameraman_final_binary_edges.png"></div>
            </div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 1.3: Derivative of Gaussian (DoG) Filter</div>
                <div class="algorithm-description">To reduce noise sensitivity inherent in finite difference operators, Gaussian smoothing was applied prior to edge detection. Derivative of Gaussian (DoG) filters were constructed by convolving the Gaussian kernel with Dx and Dy, allowing gradient estimation in a single step.</div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Gaussian Kernel (Large)</div><img src="../images/proj2/1.3/gaussian_kernel_large.png"></div>
                <div class="image-item"><div class="image-label">DoG X Kernel</div><img src="../images/proj2/1.3/DoG_x_kernel_large.png"></div>
                <div class="image-item"><div class="image-label">DoG Y Kernel</div><img src="../images/proj2/1.3/DoG_y_kernel_large.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Gradient Magnitude (DoG)</div><img src="../images/proj2/1.3/gradient_magnitude_DoG.png"></div>
                <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 1.0)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG_1.0.png"></div>
                <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 0.3 – Single)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG_single.png"></div>
                <div class="image-item"><div class="image-label">Binary Edges (DoG, Threshold 0.3 – Final)</div><img src="../images/proj2/1.3/cameraman_final_binary_edges_DoG.png"></div>
            </div>
            <div class="algorithm-description">Compared to raw finite difference outputs, DoG filtering produces significantly cleaner edges by suppressing high-frequency noise before differentiation. While some fine details are smoothed out, the main structural edges remain sharp and continuous. The prompt asked us to try two different approaches: (1) first blur the image with a Gaussian and then apply finite difference operators, and (2) directly convolve with derivative-of-Gaussian (DoG) filters. The "single" and "final" 0.3-threshold binary edge maps come from these two methods, yet they converge to nearly identical results. This shows that DoG-based edge detection is stable across both formulations when reasonable thresholds are chosen.</div>
        </div>
        <div class="evidence-section">
            <div class="evidence-title">Part 2: Fun with Frequencies</div>
            <div class="algorithm-section">
                <div class="algorithm-title">Part 2.1: Image Sharpening</div>
                <div class="algorithm-description">Using the unsharp masking technique, we sharpened both the Taj Mahal and a portrait of Henry Cavill. A Gaussian blur was first applied to extract low frequencies, which were subtracted from the original to obtain high-frequency components. Adding these back (scaled) to the original yields sharper images. This demonstrates how boosting high frequencies enhances detail while risking noise amplification.</div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Taj Mahal – Original</div><img src="../images/proj2/2.1/taj_original.png"></div>
                <div class="image-item"><div class="image-label">Taj Mahal – Blurred</div><img src="../images/proj2/2.1/taj_blurred.png"></div>
                <div class="image-item"><div class="image-label">Taj Mahal – High Frequencies</div><img src="../images/proj2/2.1/taj_high_freq.png"></div>
                <div class="image-item"><div class="image-label">Taj Mahal – Unsharp Mask</div><img src="../images/proj2/2.1/taj_unsharp_mask.png"></div>
                <div class="image-item"><div class="image-label">Taj Mahal – Sharpened Result</div><img src="../images/proj2/2.1/taj_sharpened.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Henry Cavill – Original</div><img src="../images/proj2/2.1/henry_cavill_original.png"></div>
                <div class="image-item"><div class="image-label">Sharpened (Amount 0.5)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_0.5.png"></div>
                <div class="image-item"><div class="image-label">Sharpened (Amount 2.0)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_2.0.png"></div>
                <div class="image-item"><div class="image-label">Sharpened (Amount 3.0)</div><img src="../images/proj2/2.1/henry_cavill_sharpened_3.0.png"></div>
            </div>
            <div class="algorithm-description">The Taj Mahal experiment clearly shows the separation of low and high frequencies: the blurred image captures structure, while the high-frequency residuals highlight fine details. Adding the scaled residuals yields a sharpened version with more pronounced edges. For Henry Cavill's portrait, varying the sharpening strength demonstrates the tradeoff: mild sharpening (0.5) subtly enhances detail, while stronger sharpening (3.0) increases contrast but can introduce haloing artifacts. This highlights the importance of selecting appropriate scaling factors when applying unsharp masking.</div>
            
            <div class="algorithm-section">
                <div class="algorithm-title">Part 2.2: Hybrid Images</div>
                <div class="algorithm-description">Hybrid images combine high-frequency components from one image with low-frequency components from another, creating a perceptual illusion where different images are visible at different viewing distances. The low frequencies dominate at distance while high frequencies become apparent up close.</div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Derek – Original (Aligned)</div><img src="../images/proj2/2.2/fft_derek_original.png"></div>
                <div class="image-item"><div class="image-label">Nutmeg – Original (Aligned)</div><img src="../images/proj2/2.2/fft_nutmeg_original.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Derek – Low Frequencies (Aligned, σ=7)</div><img src="../images/proj2/2.2/fft_low_freq.png"></div>
                <div class="image-item"><div class="image-label">Nutmeg – High Frequencies (Aligned, σ=5)</div><img src="../images/proj2/2.2/fft_high_freq.png"></div>
                <div class="image-item"><div class="image-label">Hybrid Image Result (Aligned)</div><img src="../images/proj2/2.2/fft_hybrid.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Happy Face – Original</div><img src="../images/proj2/2.2/happy_face.jpg"></div>
                <div class="image-item"><div class="image-label">Sad Face – Original</div><img src="../images/proj2/2.2/sad_face.jpg"></div>
                <div class="image-item"><div class="image-label">Happy-Sad Hybrid</div><img src="../images/proj2/2.2/sad_and_happy.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Sarah – Original</div><img src="../images/proj2/2.2/sarah.jpg"></div>
                <div class="image-item"><div class="image-label">Kitten – Original</div><img src="../images/proj2/2.2/kitten.jpg"></div>
                <div class="image-item"><div class="image-label">Sarah-Kitten Hybrid</div><img src="../images/proj2/2.2/sarah_and_kitten.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Low Frequency Component (σ=7)</div><img src="../images/proj2/2.2/low_freq_component7.png"></div>
                <div class="image-item"><div class="image-label">High Frequency Component (σ=5)</div><img src="../images/proj2/2.2/high_freq_component5.png"></div>
                <div class="image-item"><div class="image-label">Final Hybrid (Multi-scale)</div><img src="../images/proj2/2.2/hybrid_image5.png"></div>
            </div>
            <div class="algorithm-description">The Derek-Nutmeg hybrid demonstrates the classic hybrid image effect: from a distance, the low-frequency Derek dominates the perception, while up close, Nutmeg's high-frequency details become visible. Using σ₁=5 for high-pass filtering and σ₂=7 for low-pass filtering creates optimal frequency separation. The happy-sad face hybrid creates an emotional ambiguity that shifts with viewing distance. The Sarah-kitten hybrid showcases how drastically different subjects can be combined, with the human features visible from up close transitioning to feline features far away. The frequency analysis reveals how the hybrid preserves low frequencies from one source while incorporating high-frequency details from another, creating the perceptual duality.</div>
            
            <div class="algorithm-section">
                <div class="algorithm-title">Part 2.3: Gaussian and Laplacian Stacks</div>
                <div class="algorithm-description">Gaussian and Laplacian stacks decompose images into frequency bands while maintaining spatial resolution. The Gaussian stack progressively blurs the image at each level, while the Laplacian stack captures the frequency content between consecutive Gaussian levels, essential for multiresolution blending.</div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Apple - Gaussian Level 0</div><img src="../images/proj2/2.3/apple_gaussian_level_0.png"></div>
                <div class="image-item"><div class="image-label">Apple - Gaussian Level 1</div><img src="../images/proj2/2.3/apple_gaussian_level_1.png"></div>
                <div class="image-item"><div class="image-label">Apple - Gaussian Level 2</div><img src="../images/proj2/2.3/apple_gaussian_level_2.png"></div>
                <div class="image-item"><div class="image-label">Apple - Gaussian Level 3</div><img src="../images/proj2/2.3/apple_gaussian_level_3.png"></div>
                <div class="image-item"><div class="image-label">Apple - Gaussian Level 4</div><img src="../images/proj2/2.3/apple_gaussian_level_4.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Apple - Laplacian Level 0</div><img src="../images/proj2/2.3/apple_laplacian_level_0.png"></div>
                <div class="image-item"><div class="image-label">Apple - Laplacian Level 1</div><img src="../images/proj2/2.3/apple_laplacian_level_1.png"></div>
                <div class="image-item"><div class="image-label">Apple - Laplacian Level 2</div><img src="../images/proj2/2.3/apple_laplacian_level_2.png"></div>
                <div class="image-item"><div class="image-label">Apple - Laplacian Level 3</div><img src="../images/proj2/2.3/apple_laplacian_level_3.png"></div>
                <div class="image-item"><div class="image-label">Apple - Laplacian Level 4</div><img src="../images/proj2/2.3/apple_laplacian_level_4.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Orange - Gaussian Level 0</div><img src="../images/proj2/2.3/orange_gaussian_level_0.png"></div>
                <div class="image-item"><div class="image-label">Orange - Gaussian Level 1</div><img src="../images/proj2/2.3/orange_gaussian_level_1.png"></div>
                <div class="image-item"><div class="image-label">Orange - Gaussian Level 2</div><img src="../images/proj2/2.3/orange_gaussian_level_2.png"></div>
                <div class="image-item"><div class="image-label">Orange - Gaussian Level 3</div><img src="../images/proj2/2.3/orange_gaussian_level_3.png"></div>
                <div class="image-item"><div class="image-label">Orange - Gaussian Level 4</div><img src="../images/proj2/2.3/orange_gaussian_level_4.png"></div>
            </div>
            <div class="results-grid">
                <div class="image-item"><div class="image-label">Orange - Laplacian Level 0</div><img src="../images/proj2/2.3/orange_laplacian_level_0.png"></div>
                <div class="image-item"><div class="image-label">Orange - Laplacian Level 1</div><img src="../images/proj2/2.3/orange_laplacian_level_1.png"></div>
                <div class="image-item"><div class="image-label">Orange - Laplacian Level 2</div><img src="../images/proj2/2.3/orange_laplacian_level_2.png"></div>
                <div class="image-item"><div class="image-label">Orange - Laplacian Level 3</div><img src="../images/proj2/2.3/orange_laplacian_level_3.png"></div>
                <div class="image-item"><div class="image-label">Orange - Laplacian Level 4</div><img src="../images/proj2/2.3/orange_laplacian_level_4.png"></div>
            </div>
            <div class="algorithm-description">The Gaussian stacks show progressive blurring with σ doubling at each level, preserving overall structure while removing fine details. The Laplacian stacks reveal the frequency bands isolated at each level - Level 0 captures high-frequency details like texture, while deeper levels contain lower frequency information about shape and form. Level 4 of the Laplacian is simply the final Gaussian blur, containing only the lowest frequencies. These decompositions enable seamless multiresolution blending by allowing different frequency bands to be combined from different source images.</div>
                        <div class="algorithm-section">
                <div class="algorithm-title">Part 2.4: Multiresolution Blending (Oraple and Beyond)</div>
                <div class="algorithm-description">
                    Multiresolution blending uses Gaussian and Laplacian stacks with a blurred mask to fuse two images smoothly 
                    across a seam. This prevents sharp transitions and allows for natural composites. Following Burt and Adelson’s 
                    1983 work, we applied this technique to both the classic apple-orange "oraple" example and a custom 
                    Batman-Superman blend.
                </div>
            </div>

            <div class="results-grid">
                <div class="image-item"><div class="image-label">Apple</div><img src="../images/proj2/2.4/apple.jpeg"></div>
                <div class="image-item"><div class="image-label">Orange</div><img src="../images/proj2/2.4/orange.jpeg"></div>
                <div class="image-item"><div class="image-label">Oraple Result</div><img src="../images/proj2/2.4/oraple.png"></div>
            </div>

            <div class="algorithm-description">
                The "oraple" result shows the smooth vertical seam generated by blending Laplacian stacks of the apple and 
                orange with a Gaussian-blurred binary mask. Fine textures from both fruits are preserved without introducing 
                obvious discontinuities, confirming the stack-based blending approach works as intended.
            </div>

            <div class="results-grid">
                <div class="image-item"><div class="image-label">Superman (Resized)</div><img src="../images/proj2/2.4/batman_resized.jpg"></div>
                <div class="image-item"><div class="image-label">Batman (Resized)</div><img src="../images/proj2/2.4/superman_resized.jpg"></div>
                <div class="image-item"><div class="image-label">Batman-Superman Logo Swap</div><img src="../images/proj2/2.4/batman_superman_logo_swap.png"></div>
            </div>

            <div class="algorithm-description">
                The Batman-Superman composite applies multiresolution blending with an irregular mask. Unlike a hard cut, 
                the Gaussian mask softly transitions between the two logos, producing a fused emblem that inherits features 
                from both heroes. This demonstrates how irregular masks allow for more creative blends beyond straight seams, 
                yielding composites that feel integrated and visually cohesive.
            </div>
            <div class="results-grid">
    <div class="image-item"><div class="image-label">Sarah – Original</div><img src="../images/proj2/2.4/sarah.jpg"></div>
    <div class="image-item"><div class="image-label">Kim Jisoo – Original</div><img src="../images/proj2/2.4/kim_jisoo.jpg"></div>
    <div class="image-item"><div class="image-label">Sarah-Jisoo Vertical Blend</div><img src="../images/proj2/2.4/sarah_jisoo_vertical_blend_2.png"></div>
</div>

<div class="algorithm-description">
    For a more creative example, we applied multiresolution blending with a vertical mask to combine 
    Sarah and Kim Jisoo’s portraits. The Gaussian-blurred mask allowed for a smooth transition down 
    the vertical seam, blending facial features in a way that avoids a harsh line through the middle. 
    While perfect alignment is challenging, the Laplacian stack blending ensures that edges and textures 
    flow naturally between the two halves, producing a cohesive fused portrait.
</div>

        </div>
    </div>
</body>
</html>
